#!/usr/bin/env python3
"""
Run Hybrid Control System with Trained DQN Model
Uses trained model for emergency situations, density-based for normal traffic
"""

import os
import sys
import argparse

# Add paths
parent_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, parent_dir)
sys.path.insert(0, os.path.join(parent_dir, 'rl_module'))

import traci
import numpy as np
from stable_baselines3 import DQN

from rl_module.vanet_env import VANETTrafficEnv


class HybridDQNController:
    """
    Hybrid controller that uses:
    - Density-based control for normal traffic
    - Trained DQN model for emergency situations
    """
    
    def __init__(self, model_path, config_path):
        """
        Initialize hybrid controller.
        
        Parameters
        ----------
        model_path : str
            Path to trained DQN model (.zip file)
        config_path : str
            Path to SUMO configuration
        """
        self.model_path = model_path
        self.config_path = config_path
        self.model = None
        self.env = None
        self.mode = "DENSITY"
        
        # Statistics
        self.stats = {
            'total_steps': 0,
            'density_steps': 0,
            'rl_steps': 0,
            'emergency_detections': 0,
            'total_reward': 0,
        }
    
    def initialize(self):
        """Initialize the controller."""
        print("=" * 80)
        print("INITIALIZING HYBRID DQN CONTROLLER")
        print("=" * 80)
        print()
        
        # Load trained model
        print(f"Loading trained DQN model...")
        print(f"  Model: {self.model_path}")
        
        try:
            self.model = DQN.load(self.model_path)
            print("‚úì Model loaded successfully")
        except Exception as e:
            print(f"‚ùå Failed to load model: {e}")
            return False
        
        # Start SUMO
        print(f"\nStarting SUMO simulation...")
        print(f"  Config: {self.config_path}")
        
        sumo_binary = "sumo"
        sumo_cmd = [
            sumo_binary,
            "-c", self.config_path,
            "--start",
            "--step-length", "1",
            "--no-warnings"
        ]
        
        try:
            traci.start(sumo_cmd)
            print("‚úì SUMO started")
        except Exception as e:
            print(f"‚ùå Failed to start SUMO: {e}")
            return False
        
        # Get traffic lights
        tl_ids = traci.trafficlight.getIDList()
        print(f"‚úì Found {len(tl_ids)} traffic lights: {tl_ids}")
        
        # Build action spec
        action_spec = {}
        for tl_id in tl_ids:
            try:
                logic = traci.trafficlight.getAllProgramLogics(tl_id)[0]
                phases = [phase.state for phase in logic.phases]
                action_spec[tl_id] = phases
                print(f"  {tl_id}: {len(phases)} phases")
            except Exception as e:
                print(f"  ‚ö†Ô∏è  Error: {e}")
        
        # Create environment
        print(f"\nCreating environment...")
        env_config = {
            'beta': 20,
            'action_spec': action_spec,
            'tl_constraint_min': 5,
            'tl_constraint_max': 60,
            'sim_step': 1.0,
            'algorithm': 'DQN',
            'horizon': 1000,
        }
        
        try:
            self.env = VANETTrafficEnv(config=env_config)
            print("‚úì Environment created")
            print(f"  Observation space: {self.env.observation_space.shape}")
            print(f"  Action space: {self.env.action_space.n} actions")
        except Exception as e:
            print(f"‚ùå Failed to create environment: {e}")
            return False
        
        # Reset environment
        print(f"\nResetting environment...")
        try:
            obs, info = self.env.reset()
            print("‚úì Environment reset")
        except Exception as e:
            print(f"‚ùå Failed to reset: {e}")
            return False
        
        print()
        print("=" * 80)
        print("‚úÖ INITIALIZATION COMPLETE")
        print("=" * 80)
        print()
        
        return True
    
    def run(self, steps=3600):
        """
        Run hybrid control simulation.
        
        Parameters
        ----------
        steps : int
            Number of simulation steps
        """
        print("=" * 80)
        print("RUNNING HYBRID CONTROL WITH TRAINED DQN")
        print("=" * 80)
        print()
        print("Control Strategy:")
        print("  ‚Ä¢ Normal traffic: Density-based adaptive control")
        print("  ‚Ä¢ Emergency detected: Trained DQN model with greenwave")
        print()
        print("=" * 80)
        print()
        
        obs, info = self.env.reset()
        
        try:
            for step in range(steps):
                self.stats['total_steps'] += 1
                
                # Check for emergency vehicles
                active_emergencies = self.env.emergency_coordinator.get_active_emergency_vehicles()
                
                if len(active_emergencies) > 0:
                    # EMERGENCY MODE: Use trained DQN model
                    if self.mode != "RL-EMERGENCY":
                        self.mode = "RL-EMERGENCY"
                        self.stats['emergency_detections'] += len(active_emergencies)
                        print(f"\nüö® EMERGENCY DETECTED at step {step}!")
                        for emerg in active_emergencies:
                            print(f"   ‚Ä¢ {emerg.vehicle_id} detected by {emerg.detected_by_rsu}")
                        print(f"   Switching to TRAINED DQN control...\n")
                    
                    self.stats['rl_steps'] += 1
                    
                    # Use trained model to predict action
                    action, _states = self.model.predict(obs, deterministic=True)
                    
                    # Apply greenwave for emergencies
                    for emerg in active_emergencies:
                        greenwave_junctions = self.env.emergency_coordinator.create_greenwave(emerg)
                        if greenwave_junctions:
                            self.env.emergency_coordinator.apply_greenwave(emerg.vehicle_id, greenwave_junctions)
                
                else:
                    # DENSITY MODE: Use simple heuristic (simulated by model too for consistency)
                    if self.mode != "DENSITY":
                        self.mode = "DENSITY"
                        print(f"\n‚úÖ EMERGENCY CLEARED at step {step}")
                        print(f"   Switching back to density-based control...\n")
                    
                    self.stats['density_steps'] += 1
                    
                    # Could use density-based logic here, but for simplicity use model
                    # with lower determinism (more exploration)
                    action, _states = self.model.predict(obs, deterministic=False)
                
                # Step environment
                obs, reward, done, truncated, info = self.env.step(action)
                self.stats['total_reward'] += reward
                
                # Print progress
                if step % 50 == 0:
                    avg_reward = self.stats['total_reward'] / max(1, step + 1)
                    print(f"Step {step:4d}/{steps} | Mode: {self.mode:15s} | "
                          f"Reward: {reward:7.2f} | Avg: {avg_reward:7.2f} | "
                          f"Emergencies: {len(active_emergencies)}")
                
                if done or truncated:
                    print(f"\nEpisode ended at step {step}, resetting...")
                    obs, info = self.env.reset()
            
            # Print final statistics
            self.print_statistics()
            
        except KeyboardInterrupt:
            print("\n\n‚ö†Ô∏è  Simulation interrupted by user (Ctrl+C)")
            self.print_statistics()
        
        except Exception as e:
            print(f"\n\n‚ùå Simulation error: {e}")
            import traceback
            traceback.print_exc()
        
        finally:
            try:
                traci.close()
                print("\n‚úì SUMO connection closed")
            except:
                pass
    
    def print_statistics(self):
        """Print simulation statistics."""
        print()
        print("=" * 80)
        print("HYBRID CONTROL SIMULATION STATISTICS")
        print("=" * 80)
        print()
        
        total = self.stats['total_steps']
        density_pct = (self.stats['density_steps'] / total * 100) if total > 0 else 0
        rl_pct = (self.stats['rl_steps'] / total * 100) if total > 0 else 0
        avg_reward = self.stats['total_reward'] / total if total > 0 else 0
        
        print(f"Total steps: {total}")
        print(f"Density-based mode: {self.stats['density_steps']} steps ({density_pct:.1f}%)")
        print(f"RL emergency mode: {self.stats['rl_steps']} steps ({rl_pct:.1f}%)")
        print(f"Emergency detections: {self.stats['emergency_detections']}")
        print(f"Total reward: {self.stats['total_reward']:.2f}")
        print(f"Average reward: {avg_reward:.2f}")
        print()
        
        # Emergency statistics
        if hasattr(self.env, 'emergency_coordinator'):
            emerg_stats = self.env.emergency_coordinator.get_statistics()
            print("Emergency Coordinator Statistics:")
            print(f"  Total detections: {emerg_stats.get('total_detections', 0)}")
            print(f"  Active emergencies: {emerg_stats.get('active_emergency_vehicles', 0)}")
            print(f"  Active greenwaves: {emerg_stats.get('active_greenwaves', 0)}")
            print()
        
        if rl_pct > 0:
            print("‚úÖ HYBRID CONTROL WITH TRAINED DQN WORKING!")
            print("   System successfully used trained model during emergencies")
        else:
            print("‚ÑπÔ∏è  No emergencies detected during simulation")
        
        print()
        print("=" * 80)


def main():
    parser = argparse.ArgumentParser(description="Run hybrid control with trained DQN")
    
    parser.add_argument(
        '--model',
        type=str,
        required=True,
        help='Path to trained DQN model (.zip file)'
    )
    parser.add_argument(
        '--config',
        type=str,
        default='../sumo_simulation/simulation.sumocfg',
        help='Path to SUMO configuration file'
    )
    parser.add_argument(
        '--steps',
        type=int,
        default=3600,
        help='Number of simulation steps'
    )
    
    args = parser.parse_args()
    
    # Check if files exist
    if not os.path.exists(args.model):
        print(f"‚ùå ERROR: Model file not found: {args.model}")
        sys.exit(1)
    
    if not os.path.exists(args.config):
        print(f"‚ùå ERROR: Config file not found: {args.config}")
        sys.exit(1)
    
    # Create controller
    controller = HybridDQNController(
        model_path=args.model,
        config_path=args.config
    )
    
    # Initialize
    if not controller.initialize():
        print("‚ùå Initialization failed")
        sys.exit(1)
    
    # Run simulation
    controller.run(steps=args.steps)
    
    print("=" * 80)
    print("‚úÖ SIMULATION COMPLETE")
    print("=" * 80)


if __name__ == "__main__":
    main()
